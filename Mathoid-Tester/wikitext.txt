==Equazioni di Lorentz== Vediamo ora alcuni metodi per risolvere le equazioni che abbiamo appena visto; iniziamo dalle equazioni di Lorentz. Vogliamo cercare di capire se in linea di principio le equazioni di Lorentz sono risolvibili, e con quali condizioni iniziali. <dmath> \int_{0}^{\epsilon} x^2 m\frac{d^2x^\mu }{ds^2}=eF^{\mu \nu }(x(s))\frac{dx_\nu }{ds} </dmath> Sono quattro equazioni differenziali del second'ordine per <math>3x^\mu (s)</math>, e pertanto ammettono univocamente una soluzione con due condizioni al contorno, ossia ci aspettiamo che la soluzione esista e sia unica se sono noti <math>x^\mu (0)</math> e <math>\frac{dx^\mu }{ds}(0)</math>. Fisicamente, però, conosciamo solo posizione e velocità iniziali della particella, ossia <math>\vec{x}(0)</math> e <math>\frac{d\vec{x}}{dt}(0)=\vec{v}(0)</math>; abbiamo dunque 6 (3+3) condizioni iniziali, mentre dalle equazioni di Lorentz ce ne aspetteremmo 8 (4+4). In realtà, il problema è risolvibile, e lo si può vedere in due modi: ;covariante::dobbiamo "costruire" le 4+4 condizioni iniziali a partire dalle 3+3. Innanzitutto, <math>s</math> deve soddisfare: <dmath> \int_{0}^{\epsilon} x^2 \frac{dx^\mu }{ds}\frac{dx^\nu }{ds}\eta _{\mu \nu }=1 \quad \forall s </dmath> Ci basta però imporre questa condizione per <math>s=0</math>. Vediamo perché. Se infatti vale l'equazione di Lorentz: <dmath> \int_{0}^{\epsilon} x^2 \quad \frac{d}{ds}\left(\frac{dx^\mu }{ds}\frac{dx_\mu }{ds}\right)=2\frac{d^2 x^\mu }{ds^2}\frac{dx_\mu }{ds}=\frac{2}{m}eF^{[\mu \nu ]}(x(s))\frac{dx_{(\nu}}{ds}\frac{dx_{\mu )}}{ds}=0 </dmath> Quindi, supponendo valide le equazioni di Lorentz, la quantità <math>\frac{dx^\mu }{ds}\frac{dx^\nu }{ds}\eta _{\mu \nu }</math> è costante, e se vale 1 per <math>s=0</math> varrà 1 per ogni <math>s</math>. La quadrivelocità, dunque, dovrà essere tale per cui inizialmente <math>u^\mu u^\nu \eta _{\mu \nu }=1</math>, e dunque non è un quadrivettore arbitrario. Supponiamo dunque di conoscere <math>\vec{x}(0)</math> e <math>\vec{v}(0)</math>, allora posto ad esempio <math>x^\mu (0)= (x^0 (0)=0; \vec{x}(0))</math>, si ha: <dmath> \int_{0}^{\epsilon} x^2 \frac{dx^\mu }{ds}(0)=\frac{1}{\sqrt{1-v^2}}(1;\vec{v}(0)) </dmath> In questo modo è soddisfatto il vincolo <math>u^\mu u^\nu \eta _{\mu \nu }=1</math> per <math>s=0</math>, e dunque per ogni <math>s</math>. ;non covariante::passiamo dalle incognite <math>x^\mu (s)</math> a <math>\vec{x}(t)</math>, esprimendo tutto in termini di <math>t</math> invece che di <math>s</math>: <dmath> \int_{0}^{\epsilon} x^2 0=H^\mu := m\frac{du^\mu }{ds}-eF^{\mu \nu }(x)u_\nu = \gamma \left[m\frac{d}{dt}\left(\gamma \frac{dx^\mu }{dt}\right)-eF^{\mu \nu }(x)\frac{dx_\nu }{dt}\right] </dmath> Queste sono quattro equazioni differenziali del second'ordine rispetto alle tre incognite <math>\vec{x}(t)</math>. Quindi, al posto di <math>\frac{dx^\mu }{dt}</math> si trova <math>(1;\frac{d\vec{x}(t)}{dt})</math>, e <math>\gamma =\frac{1}{\sqrt{1-\left(\frac{d\vec{x}}{dt}\right)^2}}</math>. Vediamo ora che una di queste equazioni è ridondante: <dmath> \int_{0}^{\epsilon} x^2 u_\mu H^\mu = \underbrace{mu_\mu \frac{du^\mu }{ds}}_{=0} - \underbrace{eF^{[\mu \nu ]}u_{(\mu }u_{\nu )}}_{=0}=0 </dmath> Esiste dunque una combinazione lineare delle <math>H^\mu </math> che è nulla, e pertanto basta risolverne tre per risolverle tutte (l'ultima è determinata da questa combinazione lineare). Infatti, ad esempio: <dmath label="0"> u^0 H_0 - \vec{u}\cdot \vec{H}=0 \quad \Rightarrow \quad H^0=\frac{\vec{u}\cdot \vec{H}}{u^0}</dmath> Basta quindi risolvere le componenti spaziali di <math>\vec{H}=0</math>: <dmath label="1"> m\frac{d}{dt}\left(\frac{\vec{v}(t)}{\sqrt{1-\vec{v}^2(t)}}\right)=e\left[\vec{E}(\vec{x}(t),t)+\vec{v}(t)\times \vec{B}(\vec{x}(t),t)\right]</dmath> che sono equazioni differenziali rispetto alle incognite <math>\vec{x}(t)</math> per le quali conosciamo le condizioni iniziali; pertanto, sono risolvibili. Inoltre: <dmath> \int_{0}^{\epsilon} x^2 H^0=0 \quad \Rightarrow \quad \frac{d}{dt}\left[\frac{m}{\sqrt{1-\vec{v}^2 (t)}}\right]=e\vec{E}(\vec{x}(t),t)\cdot \vec{v}(t) </dmath> (che è l'equazione della potenza). Poiché per ( ([[Elettrodinamica classica/Richiami di relatività ristretta/Cinematica relativistica/Problema di Cauchy per le equazioni del moto#Equazioni di Lorentz]]) ) <math>\vec{H}=0</math> implica <math>H^0=0</math>, l'equazione della potenza è implicata dalla ( ([[Elettrodinamica classica/Richiami di relatività ristretta/Cinematica relativistica/Problema di Cauchy per le equazioni del moto#Equazioni di Lorentz]]) ). ==Identità di Bianchi e invarianza di gauge== Vediamo ora invece come si risolvono in generale le identità di Bianchi: <dmath> \int_{0}^{\epsilon} x^2 \varepsilon ^{\mu \nu \rho \sigma }\partial _\nu F_{\rho \sigma }=0 </dmath> Il ''lemma di Poincaré'' ci permette di risolvere in generalità queste equazioni: questo lemma asserisce che l'equazione è vera se e solo se il tensore antisimmetrico <math>F_{\mu \nu }</math> si può scrivere come: <dmath> \int_{0}^{\epsilon} x^2 F_{\mu \nu }=\partial _\mu A_\nu -\partial _\nu A_\mu </dmath> ove <math>A_\mu </math> è un quadrivettore. Ciò è inoltre vero localmente, ossia in un intorno sufficientemente piccolo del punto considerato; globalmente, invece, ciò può non essere vero. Nel nostro caso (cioè in spazi del tipo di <math>\mathbb {R}^ n</math>), tuttavia, ciò è sempre verificato; <math>A_\mu </math> è detto ''quadripotenziale''. Non verifichiamo qui il lemma, ma ci limitiamo a dimostrarne una implicazione, ossia che se <math>F_{\mu \nu }</math> può essere scritto come <math>F_{\mu \nu }=\partial _\mu A_\nu -\partial _\nu A_\mu </math>, allora valgono le identità di Bianchi. Vediamolo: <dmath> \int_{0}^{\epsilon} x^2 \quad \varepsilon ^{\mu \nu \rho \sigma }\partial _\nu F_{\rho \sigma } = \varepsilon ^{\mu \nu \rho \sigma }\partial _\nu \left(\partial _\rho A_\sigma - \partial _\sigma A_\rho \right)=2\varepsilon ^{\mu [\nu \rho ]\sigma }\partial _{(\nu }\partial _{\sigma )}A_\sigma =0 </dmath> ove alla seconda uguaglianza abbiamo eseguito la moltiplicazione e nel secondo termine rinominato <math>\rho </math> con <math>\sigma </math> e <math>\sigma </math> con <math>\rho </math>. Il quadrivettore <math>A_\mu </math>, però, è particolare: non è univocamente definito. Ciò significa che dato un <math>F_{\mu \nu }</math> esistono più <math>A_\mu </math> tali che <math>F_{\mu \nu }=\partial _\mu A_\nu -\partial _\nu A_\mu </math>. Questa ‘‘ridondanza‘‘ per <math>A_\mu </math> è detta ''invarianza di gauge''; per comprenderla meglio, consideriamo la trasformazione: <dmath> \int_{0}^{\epsilon} x^2 A_\mu \longrightarrow A_\mu +\partial _\mu \Lambda </dmath> con <math>\Lambda (x)</math> campo scalare generico. Allora si ha: <dmath> \int_{0}^{\epsilon} x^2 F_{\mu \nu }\longrightarrow \partial _\mu ( A_\nu +\partial _\nu \Lambda ) - \partial _\nu (A_\mu + \partial _\mu \Lambda )= \partial _\mu A_\nu -\partial _\nu A_\mu + \partial _\mu \partial _\nu \Lambda - \partial _\nu \partial _\mu \Lambda = F_{\mu \nu } </dmath> e quindi la trasformazione <math>A_\mu \longrightarrow A_\mu +\partial _\mu \Lambda </math> lascia invariato <math>F_{\mu \nu }</math>, ossia i campi elettrico e magnetico. Da notare che mentre <math>F_{\mu \nu }</math> ha un significato fisico effettivo (ossia lo si può misurare), <math>A_\mu </math> no (perché i potenziali sono definiti a meno di invarianza di gauge). Si possono, volendo, imporre condizioni (dette di ''gauge fixing'') che rendano <math>A_\mu </math> ben definito. Un esempio di gauge fixing è la ''gauge di Lorenz'': <dmath> \int_{0}^{\epsilon} x^2 \partial _\mu A^\mu =0 </dmath> In questo caso, infatti, applicando la trasformazione di prima si ha che: <dmath> \int_{0}^{\epsilon} x^2 \partial _\mu {A'}^\mu = \underbrace{\partial _\mu A^\mu }_{=0} +\partial _\mu \partial ^\mu \Lambda = \partial _\mu \partial ^\mu \Lambda \neq 0 </dmath> Quindi in questo caso, a meno che <math>\Lambda </math> sia tale che <math>\partial _\mu \partial ^\mu \Lambda = 0</math> (in questo caso si parla di ''gauge residua''), <math>A_\mu </math> è univocamente definito. ==Equazioni di Maxwell e quadricorrente== Ora, invece, come si risolvono le equazioni dinamiche? <dmath> \int_{0}^{\epsilon} x^2 \partial _\mu F^{\mu \nu }=j^\nu </dmath> Innanzitutto, affinché quest'equazione sia soddisfatta, <math>j^\nu </math> non può essere un quadrivettore arbitrario. Infatti: <dmath> \int_{0}^{\epsilon} x^2 \partial _{(\nu }\partial _{\mu )}F^{[\mu \nu ]}=\partial _\nu j^\nu \quad \Rightarrow \quad \partial _\nu j^\nu =0 </dmath> Quest'equazione esprime la ''conservazione della carica''. Espressa in notazione tridimensionale diventa: <dmath> \int_{0}^{\epsilon} x^2 \frac{\partial \rho }{\partial t}+\vec{\nabla }\cdot \vec{j}=0 </dmath> che è proprio l'''equazione di continuità'' della carica. Ci chiediamo ora: che espressione esplicita ha <math>j^\nu </math>? Il caso più semplice possibile è quello di una particella carica in moto. Se <math>e</math> è la sua carica, <math>\vec{x}(t)</math> la sua traiettoria e <math>\vec{v}(t)</math> la sua velocità, allora in notazione tridimensionale si ha: <dmath> \int_{0}^{\epsilon} x^2 \rho (\vec{x},t)=e \delta ^{(3)}(\vec{x}-\vec{x}(t)) \quad \vec{j} (\vec{x},t)=e\vec{v}(t)\delta ^{(3)}(\vec{x}-\vec{x}(t)) </dmath> ove <math>\delta ^{(3)}</math> è la ''delta di Dirac tridimensionale''. In generale, quindi, la quadricorrente è un quadrivettore le cui componenti sono distribuzioni matematiche. (1,0)500 ===Cenni sulle distribuzioni=== <dmath> \int_{0}^{\epsilon} x^2 \int \delta (x-a) \varphi (x) dx=\varphi (a) \quad \varphi \in C^\infty </dmath> <dmath> \int_{0}^{\epsilon} x^2 \int \frac{d}{dx}\delta (x-a) \varphi (x)dx=-\int \delta (x-a)\frac{d}{dx}\varphi (x) dx=-\varphi '(a) </dmath> <dmath> \int_{0}^{\epsilon} x^2 \int \frac{d^ n}{dx^ n}\delta (x-a) \varphi (x) dx = (-1)^ n \varphi ^{(n)} (a) </dmath> <dmath> \int_{0}^{\epsilon} x^2 \delta (f(x))=\sum _{\mbox{zeri di } f} \frac{\delta (x-x_ n)}{|f'(x_ n)|} \quad f(x) \delta (x-a) = f(a) \delta (x-a) </dmath> Il prodotto di due distribuzioni non è una distribuzione: <math>\delta (x) \delta (x)=\delta (0) \delta (x)</math>, infatti, non ha senso. La <math>\delta </math> inoltre si può generalizzare a più dimensioni: <dmath> \int_{0}^{\epsilon} x^2 \delta ^{(4)}(x-a)=\delta (x^0-a^0) \cdots \delta (x^3-a^3) </dmath> Trasformata di Fourier di una distribuzione <math>F(x)</math>: <dmath> \int_{0}^{\epsilon} x^2 \hat{F}(k)=\frac{1}{(2\pi )^2}\int e^{-ikx}F(x)d^4 x </dmath> <dmath> \int_{0}^{\epsilon} x^2 F(x)=\frac{1}{(2\pi )^2} \int e^{ikx}\hat{F}(k)d^4 k </dmath> Una trasformata notevole è quella della <math>\delta </math>: <dmath> \int_{0}^{\epsilon} x^2 \hat{\delta }(k)=\frac{1}{(2\pi )^2} </dmath> (1,0)500 <references/>
